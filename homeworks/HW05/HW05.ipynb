{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4227dfab",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 740) (1324575026.py, line 740)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 740\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"\\n\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 740)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, roc_curve, \n",
    "                             precision_score, recall_score, f1_score, \n",
    "                             confusion_matrix, classification_report)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "df = pd.read_csv('S05-hw-dataset.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"1. ОБЩАЯ ИНФОРМАЦИЯ О ДАТАСЕТЕ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Размер датасета: {df.shape[0]} строк, {df.shape[1]} столбцов\")\n",
    "\n",
    "print(\"\\nПервые 5 строк датасета:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nИнформация о столбцах и типах данных:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"2. БАЗОВЫЕ СТАТИСТИКИ ДЛЯ ЧИСЛОВЫХ ПРИЗНАКОВ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "display(df.describe().T.style.background_gradient(cmap='Blues', axis=0))\n",
    "\n",
    "print(f\"\\nПропущенные значения:\")\n",
    "missing_values = df.isnull().sum()\n",
    "display(missing_values[missing_values > 0])\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"3. АНАЛИЗ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ (default)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "target_distribution = df['default'].value_counts(normalize=True) * 100\n",
    "print(\"\\nРаспределение целевой переменной:\")\n",
    "print(f\"0 (нет дефолта): {target_distribution[0]:.2f}%\")\n",
    "print(f\"1 (дефолт): {target_distribution[1]:.2f}%\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].bar(['Нет дефолта (0)', 'Дефолт (1)'], target_distribution.values, color=['green', 'red'])\n",
    "axes[0].set_title('Распределение целевой переменной', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Процент (%)', fontsize=12)\n",
    "for i, v in enumerate(target_distribution.values):\n",
    "    axes[0].text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "\n",
    "axes[1].pie(target_distribution.values, labels=target_distribution.index, \n",
    "           autopct='%1.1f%%', colors=['green', 'red'], startangle=90)\n",
    "axes[1].set_title('Доля классов', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/target_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if 'client_id' in numeric_cols:\n",
    "    numeric_cols.remove('client_id')\n",
    "\n",
    "corr_subset = df[numeric_cols]\n",
    "\n",
    "correlation_matrix = corr_subset.corr()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Корреляционная матрица признаков', fontsize=16, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "target_corr = correlation_matrix['default'].sort_values(ascending=False)\n",
    "print(\"\\nКорреляция признаков с целевой переменной (default):\")\n",
    "display(pd.DataFrame(target_corr).style.background_gradient(cmap='RdBu_r', axis=0))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"4. ПОДГОТОВКА ПРИЗНАКОВ И ТАРГЕТА\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X = df.drop(['default', 'client_id'], axis=1)\n",
    "y = df['default']\n",
    "\n",
    "print(f\"Размер матрицы признаков X: {X.shape}\")\n",
    "print(f\"Размер вектора таргета y: {y.shape}\")\n",
    "\n",
    "print(\"\\nТипы данных в X:\")\n",
    "print(X.dtypes.value_counts())\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f\"\\nКатегориальные признаки: {list(categorical_cols)}\")\n",
    "    for col in categorical_cols:\n",
    "        print(f\"{col}: {X[col].unique()[:10]}...\")\n",
    "else:\n",
    "    print(\"\\nВсе признаки являются числовыми (категориальных признаков нет)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"5. TRAIN/TEST-СПЛИТ И БЕЙЗЛАЙН-МОДЕЛЬ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.25,        \n",
    "    random_state=42,       \n",
    "    stratify=y            \n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape[0]} объектов\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape[0]} объектов\")\n",
    "\n",
    "print(f\"\\nРаспределение классов в обучающей выборке:\")\n",
    "train_dist = y_train.value_counts(normalize=True)\n",
    "print(f\"0 (нет дефолта): {train_dist[0]:.2%}\")\n",
    "print(f\"1 (дефолт): {train_dist[1]:.2%}\")\n",
    "\n",
    "print(f\"\\nРаспределение классов в тестовой выборке:\")\n",
    "test_dist = y_test.value_counts(normalize=True)\n",
    "print(f\"0 (нет дефолта): {test_dist[0]:.2%}\")\n",
    "print(f\"1 (дефолт): {test_dist[1]:.2%}\")\n",
    "\n",
    "\n",
    "dummy_models = {\n",
    "    'most_frequent': DummyClassifier(strategy='most_frequent', random_state=42),\n",
    "    'stratified': DummyClassifier(strategy='stratified', random_state=42)\n",
    "}\n",
    "\n",
    "baseline_results = []\n",
    "\n",
    "for name, model in dummy_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    baseline_results.append({\n",
    "        'Model': f'Dummy ({name})',\n",
    "        'Accuracy': accuracy,\n",
    "        'ROC-AUC': roc_auc,\n",
    "        'Description': f'Предсказывает {name}'\n",
    "    })\n",
    "\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "print(\"\\nРезультаты бейзлайн-моделей:\")\n",
    "display(baseline_df.style.format({'Accuracy': '{:.4f}', 'ROC-AUC': '{:.4f}'})\n",
    "       .background_gradient(subset=['Accuracy', 'ROC-AUC'], cmap='YlOrRd'))\n",
    "\n",
    "\n",
    "best_baseline = dummy_models['stratified']\n",
    "y_pred_baseline = best_baseline.predict(X_test)\n",
    "y_pred_proba_baseline = best_baseline.predict_proba(X_test)[:, 1] if hasattr(best_baseline, 'predict_proba') else None\n",
    "\n",
    "print(f\"\\nДля дальнейшего сравнения используем DummyClassifier(strategy='stratified')\")\n",
    "print(f\"Accuracy лучшей бейзлайн-модели: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"6. ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ И ПОДБОР ГИПЕРПАРАМЕТРОВ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "logreg_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Стандартизация признаков\n",
    "    ('logreg', LogisticRegression(\n",
    "        max_iter=1000,             # Увеличиваем максимальное количество итераций\n",
    "        random_state=42,           # Для воспроизводимости\n",
    "        solver='lbfgs'             # Алгоритм оптимизации\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"Создан пайплайн:\")\n",
    "for step_name, step in logreg_pipeline.steps:\n",
    "    print(f\"  - {step_name}: {step}\")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'logreg__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0],  \n",
    "    'logreg__penalty': ['l2'],  \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    logreg_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,                    # 5-кратная кросс-валидация\n",
    "    scoring='roc_auc',       # Оптимизируем по ROC-AUC\n",
    "    n_jobs=-1,               # Используем все доступные ядра\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nНачинаем подбор гиперпараметров...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"\\nРезультаты GridSearchCV:\")\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "print(f\"Лучший score (ROC-AUC) на кросс-валидации: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results = cv_results.sort_values('mean_test_score', ascending=False)\n",
    "\n",
    "print(\"\\nТоп-5 комбинаций гиперпараметров:\")\n",
    "top_5_results = cv_results[['params', 'mean_test_score', 'std_test_score']].head()\n",
    "display(top_5_results.style.format({'mean_test_score': '{:.4f}', 'std_test_score': '{:.4f}'})\n",
    "       .background_gradient(subset=['mean_test_score'], cmap='YlGn'))\n",
    "\n",
    "\n",
    "c_values = []\n",
    "mean_scores = []\n",
    "std_scores = []\n",
    "\n",
    "for c in param_grid['logreg__C']:\n",
    "    mask = cv_results['param_logreg__C'] == c\n",
    "    if mask.any():\n",
    "        c_values.append(c)\n",
    "        mean_scores.append(cv_results[mask]['mean_test_score'].mean())\n",
    "        std_scores.append(cv_results[mask]['std_test_score'].mean())\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(c_values, mean_scores, yerr=std_scores, \n",
    "             marker='o', markersize=8, capsize=5, linewidth=2)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Параметр регуляризации C (log scale)', fontsize=12)\n",
    "plt.ylabel('ROC-AUC (кросс-валидация)', fontsize=12)\n",
    "plt.title('Влияние параметра C на качество модели', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/c_parameter_effect.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nОптимальное значение C: {grid_search.best_params_['logreg__C']}\")\n",
    "\n",
    "\n",
    "best_logreg = grid_search.best_estimator_\n",
    "\n",
    "y_pred_logreg = best_logreg.predict(X_test)\n",
    "y_pred_proba_logreg = best_logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "logreg_accuracy = accuracy_score(y_test, y_pred_logreg)\n",
    "logreg_roc_auc = roc_auc_score(y_test, y_pred_proba_logreg)\n",
    "logreg_precision = precision_score(y_test, y_pred_logreg)\n",
    "logreg_recall = recall_score(y_test, y_pred_logreg)\n",
    "logreg_f1 = f1_score(y_test, y_pred_logreg)\n",
    "\n",
    "print(\"\\nМетрики лучшей логистической регрессии на тестовой выборке:\")\n",
    "print(f\"Accuracy: {logreg_accuracy:.4f}\")\n",
    "print(f\"ROC-AUC: {logreg_roc_auc:.4f}\")\n",
    "print(f\"Precision: {logreg_precision:.4f}\")\n",
    "print(f\"Recall: {logreg_recall:.4f}\")\n",
    "print(f\"F1-Score: {logreg_f1:.4f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_logreg)\n",
    "print(\"\\nМатрица ошибок:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Предсказано 0', 'Предсказано 1'],\n",
    "            yticklabels=['Истинное 0', 'Истинное 1'])\n",
    "plt.title('Матрица ошибок логистической регрессии', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Истинный класс', fontsize=12)\n",
    "plt.xlabel('Предсказанный класс', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nОтчет классификации:\")\n",
    "print(classification_report(y_test, y_pred_logreg, \n",
    "                           target_names=['Нет дефолта (0)', 'Дефолт (1)']))\n",
    "\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_logreg)\n",
    "\n",
    "if y_pred_proba_baseline is not None:\n",
    "    fpr_baseline, tpr_baseline, _ = roc_curve(y_test, y_pred_proba_baseline)\n",
    "    roc_auc_baseline = roc_auc_score(y_test, y_pred_proba_baseline)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "         label=f'Логистическая регрессия (ROC-AUC = {logreg_roc_auc:.3f})')\n",
    "\n",
    "if y_pred_proba_baseline is not None:\n",
    "    plt.plot(fpr_baseline, tpr_baseline, color='blue', lw=2, linestyle='--',\n",
    "             label=f'Бейзлайн (ROC-AUC = {roc_auc_baseline:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Случайный классификатор')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=12)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=12)\n",
    "plt.title('ROC-кривые классификаторов', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', s=100, \n",
    "            label=f'Оптимальный порог = {optimal_threshold:.3f}', zorder=5)\n",
    "plt.annotate(f'Порог: {optimal_threshold:.3f}', \n",
    "             xy=(fpr[optimal_idx], tpr[optimal_idx]),\n",
    "             xytext=(fpr[optimal_idx] + 0.1, tpr[optimal_idx] - 0.1),\n",
    "             arrowprops=dict(arrowstyle='->', color='red'),\n",
    "             fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nОптимальный порог классификации (ближайший к (0,1)): {optimal_threshold:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"7. СРАВНЕНИЕ МОДЕЛЕЙ И ИТОГОВЫЕ ВЫВОДЫ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_data = [\n",
    "    {\n",
    "        'Модель': 'Dummy (stratified)',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_baseline),\n",
    "        'ROC-AUC': roc_auc_baseline if y_pred_proba_baseline is not None else 'N/A',\n",
    "        'Precision': 'N/A',\n",
    "        'Recall': 'N/A',\n",
    "        'F1-Score': 'N/A',\n",
    "        'Описание': 'Случайное предсказание с сохранением распределения классов'\n",
    "    },\n",
    "    {\n",
    "        'Модель': 'Logistic Regression',\n",
    "        'Accuracy': logreg_accuracy,\n",
    "        'ROC-AUC': logreg_roc_auc,\n",
    "        'Precision': logreg_precision,\n",
    "        'Recall': logreg_recall,\n",
    "        'F1-Score': logreg_f1,\n",
    "        'Описание': f\"Логистическая регрессия с C={grid_search.best_params_['logreg__C']}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\nСРАВНИТЕЛЬНАЯ ТАБЛИЦА МОДЕЛЕЙ\")\n",
    "print(\"-\" * 100)\n",
    "display(comparison_df.style.format({\n",
    "    'Accuracy': '{:.4f}',\n",
    "    'ROC-AUC': '{:.4f}',\n",
    "    'Precision': '{:.4f}',\n",
    "    'Recall': '{:.4f}',\n",
    "    'F1-Score': '{:.4f}'\n",
    "}).background_gradient(subset=['Accuracy', 'ROC-AUC', 'Precision', 'Recall', 'F1-Score'], \n",
    "                     cmap='YlGnBu'))\n",
    "\n",
    "if y_pred_proba_baseline is not None:\n",
    "    accuracy_improvement = (logreg_accuracy - accuracy_score(y_test, y_pred_baseline)) / accuracy_score(y_test, y_pred_baseline) * 100\n",
    "    roc_auc_improvement = (logreg_roc_auc - roc_auc_baseline) / roc_auc_baseline * 100\n",
    "    \n",
    "    print(f\"\\nОтносительное улучшение по сравнению с бейзлайном:\")\n",
    "    print(f\"Accuracy: +{accuracy_improvement:.2f}%\")\n",
    "    print(f\"ROC-AUC: +{roc_auc_improvement:.2f}%\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Сравнение метрик качества моделей', fontsize=16, fontweight='bold')\n",
    "\n",
    "metrics = ['Accuracy', 'ROC-AUC', 'Precision', 'Recall', 'F1-Score']\n",
    "metric_values_logreg = [logreg_accuracy, logreg_roc_auc, logreg_precision, logreg_recall, logreg_f1]\n",
    "\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    \n",
    "    values = []\n",
    "    labels = []\n",
    "    \n",
    "    \n",
    "    if metric in ['Accuracy', 'ROC-AUC']:\n",
    "        if metric == 'Accuracy':\n",
    "            values.append(accuracy_score(y_test, y_pred_baseline))\n",
    "            labels.append('Dummy')\n",
    "        elif metric == 'ROC-AUC' and y_pred_proba_baseline is not None:\n",
    "            values.append(roc_auc_baseline)\n",
    "            labels.append('Dummy')\n",
    "    \n",
    "    \n",
    "    values.append(metric_values_logreg[idx])\n",
    "    labels.append('LogReg')\n",
    "    \n",
    "    \n",
    "    bars = ax.bar(labels, values, color=['skyblue', 'lightcoral'][:len(labels)])\n",
    "    ax.set_title(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Значение', fontsize=10)\n",
    "    ax.set_ylim([0, 1.1])\n",
    "    \n",
    "    \n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{value:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "logreg_model = best_logreg.named_steps['logreg']\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Признак': feature_names,\n",
    "    'Коэффициент': logreg_model.coef_[0],\n",
    "    'Абсолютное значение': np.abs(logreg_model.coef_[0])\n",
    "})\n",
    "\n",
    "\n",
    "feature_importance = feature_importance.sort_values('Абсолютное значение', ascending=False)\n",
    "\n",
    "print(\"\\nВАЖНОСТЬ ПРИЗНАКОВ В ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ\")\n",
    "print(\"(Отсортировано по абсолютному значению коэффициента)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "top_n = 10\n",
    "print(f\"\\nТоп-{top_n} самых важных признаков:\")\n",
    "display(feature_importance.head(top_n).style.format({'Коэффициент': '{:.4f}', 'Абсолютное значение': '{:.4f}'})\n",
    "       .background_gradient(subset=['Абсолютное значение'], cmap='Reds'))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(feature_importance.head(15)['Признак'][::-1], \n",
    "                feature_importance.head(15)['Абсолютное значение'][::-1],\n",
    "                color='steelblue')\n",
    "\n",
    "plt.xlabel('Абсолютное значение коэффициента', fontsize=12)\n",
    "plt.title('Топ-15 самых важных признаков для прогнозирования дефолта', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    coeff = feature_importance.head(15).iloc[-(i+1)]['Коэффициент']\n",
    "    plt.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{coeff:.3f}', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ИТОГОВЫЙ ОТЧЕТ И ВЫВОДЫ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "1. КРАТКОЕ РЕЗЮМЕ ЭКСПЕРИМЕНТА:\n",
    "---------------------------------------------------------------\n",
    "- Датасет содержал {} наблюдений с {} признаками.\n",
    "- Целевая переменная (дефолт по кредиту) распределена: {}% - нет дефолта, {}% - дефолт.\n",
    "- Данные были разделены на обучающую (75%) и тестовую (25%) выборки с сохранением баланса классов.\n",
    "- Бейзлайн-модель (DummyClassifier) показала accuracy = {:.4f}.\n",
    "- Логистическая регрессия с подбором гиперпараметров показала accuracy = {:.4f}.\n",
    "\"\"\".format(\n",
    "    df.shape[0], \n",
    "    X.shape[1],\n",
    "    round(target_distribution[0], 1),\n",
    "    round(target_distribution[1], 1),\n",
    "    accuracy_score(y_test, y_pred_baseline),\n",
    "    logreg_accuracy\n",
    "))\n",
    "\n",
    "print(\"\"\"\n",
    "2. СРАВНЕНИЕ МОДЕЛЕЙ:\n",
    "---------------------------------------------------------------\n",
    "- Логистическая регрессия превзошла бейзлайн-модель по всем метрикам.\n",
    "- Улучшение accuracy: {:.2f}% (с {:.4f} до {:.4f}).\n",
    "- ROC-AUC логистической регрессии составил {:.4f}, что указывает на хорошую разделяющую способность.\n",
    "- Оптимальное значение параметра регуляризации C = {}.\n",
    "\"\"\".format(\n",
    "    accuracy_improvement,\n",
    "    accuracy_score(y_test, y_pred_baseline),\n",
    "    logreg_accuracy,\n",
    "    logreg_roc_auc,\n",
    "    grid_search.best_params_['logreg__C']\n",
    "))\n",
    "\n",
    "print(\"\"\"\n",
    "3. ВЛИЯНИЕ ПАРАМЕТРА РЕГУЛЯРИЗАЦИИ C:\n",
    "---------------------------------------------------------------\n",
    "- При очень маленьких значениях C (сильная регуляризация) модель недообучается.\n",
    "- При очень больших значениях C (слабая регуляризация) модель может переобучаться.\n",
    "- Оптимальное значение C = {} обеспечивает баланс между смещением и дисперсией.\n",
    "- При этом значении модель показывает стабильное качество на кросс-валидации.\n",
    "\"\"\".format(grid_search.best_params_['logreg__C']))\n",
    "\n",
    "print(\"\"\"\n",
    "4. АНАЛИЗ ВАЖНЫХ ПРИЗНАКОВ:\n",
    "---------------------------------------------------------------\n",
    "Наиболее важными признаками для прогнозирования дефолта оказались:\n",
    "1. {} (коэффициент: {:.3f})\n",
    "2. {} (коэффициент: {:.3f})\n",
    "3. {} (коэффициент: {:.3f})\n",
    "\n",
    "Положительные коэффициенты увеличивают вероятность дефолта,\n",
    "отрицательные коэффициенты уменьшают вероятность дефолта.\n",
    "\"\"\".format(\n",
    "    feature_importance.iloc[0]['Признак'], feature_importance.iloc[0]['Коэффициент'],\n",
    "    feature_importance.iloc[1]['Признак'], feature_importance.iloc[1]['Коэффициент'],\n",
    "    feature_importance.iloc[2]['Признак'], feature_importance.iloc[2]['Коэффициент']\n",
    "))\n",
    "\n",
    "print(\"\"\"\n",
    "5. ПРАКТИЧЕСКИЕ ВЫВОДЫ И РЕКОМЕНДАЦИИ:\n",
    "---------------------------------------------------------------\n",
    "1. Логистическая регрессия показала себя как эффективная модель для \n",
    "   прогнозирования кредитных дефолтов с accuracy {:.1%}.\n",
    "\n",
    "2. Модель хорошо различает классы (ROC-AUC = {:.3f}), что делает её пригодной \n",
    "   для задач бинарной классификации с несбалансированными данными.\n",
    "\n",
    "3. Для улучшения модели можно рассмотреть:\n",
    "   - Добавление взаимодействий признаков\n",
    "   - Использование более сложных методов обработки несбалансированности\n",
    "   - Применение других алгоритмов (Random Forest, Gradient Boosting) для сравнения\n",
    "\n",
    "4. При внедрении в производство рекомендуется:\n",
    "   - Регулярно переобучать модель на новых данных\n",
    "   - Мониторить смещение данных (data drift)\n",
    "   - Использовать калибровку вероятностей для получения реалистичных оценок\n",
    "\"\"\".format(logreg_accuracy, logreg_roc_auc))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ЭКСПЕРИМЕНТ УСПЕШНО ЗАВЕРШЕН\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "\n",
    "\n",
    "joblib.dump(best_logreg, 'artifacts/best_logreg_model.pkl')\n",
    "print(\"Лучшая модель сохранена в файл: 'artifacts/best_logreg_model.pkl'\")\n",
    "\n",
    "\n",
    "results_summary = {\n",
    "    'best_params': grid_search.best_params_,\n",
    "    'test_accuracy': logreg_accuracy,\n",
    "    'test_roc_auc': logreg_roc_auc,\n",
    "    'test_precision': logreg_precision,\n",
    "    'test_recall': logreg_recall,\n",
    "    'test_f1': logreg_f1,\n",
    "    'feature_importance': feature_importance.to_dict(),\n",
    "    'comparison_results': comparison_df.to_dict()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('artifacts/experiment_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=4, default=str)\n",
    "\n",
    "print(\"Результаты эксперимента сохранены в файл: 'artifacts/experiment_results.json'\")\n",
    "\n",
    "# Сохраняем финальную таблицу сравнения\n",
    "comparison_df.to_csv('artifacts/models_comparison.csv', index=False, encoding='utf-8')\n",
    "print(\"Таблица сравнения моделей сохранена в файл: 'artifacts/models_comparison.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
